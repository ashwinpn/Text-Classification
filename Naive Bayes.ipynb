{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# feature extraction\n\ndef word_feats(words):\n    return dict([(word,True) for word in words])\n\nnltk.download()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "NLTK Downloader\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> d)\nCommand 'd)' unrecognized\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> d\n\nDownload which package (l=list; x=cancel)?\n  Identifier> movie_reviews\n    Downloading package movie_reviews to /home/nbuser/nltk_data...\n      Unzipping corpora/movie_reviews.zip.\n\n---------------------------------------------------------------------------\n    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n---------------------------------------------------------------------------\nDownloader> q\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Not using cross validation here\n\nimport nltk.classify.util\nfrom nltk.classify import NaiveBayesClassifier\nfrom nltk.corpus import movie_reviews\n\n# featstructs\ndef word_feats(words):\n    return dict([(word,True) for word in words])\n\nnegids = movie_reviews.fileids('neg')\nposids = movie_reviews.fileids('pos')\n\nnegfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\nposfeats = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n\n# you might get an error here that the slices are not integers; \n# check whether they are integers or not.\n\nnegcutoff = len(negfeats)*3//4\nposcutoff = len(posfeats)*3//4\n\ntrainfeats = negfeats[:negcutoff] + posfeats[:poscutoff]\ntestfeats = negfeats[negcutoff:] + posfeats[poscutoff:]\n#print('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n \nclassifier = NaiveBayesClassifier.train(trainfeats)\nprint('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\nclassifier.show_most_informative_features()\n\n",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "accuracy: 0.728\nMost Informative Features\n             magnificent = True              pos : neg    =     15.0 : 1.0\n             outstanding = True              pos : neg    =     13.6 : 1.0\n               insulting = True              neg : pos    =     13.0 : 1.0\n              vulnerable = True              pos : neg    =     12.3 : 1.0\n               ludicrous = True              neg : pos    =     11.8 : 1.0\n                  avoids = True              pos : neg    =     11.7 : 1.0\n             uninvolving = True              neg : pos    =     11.7 : 1.0\n             fascination = True              pos : neg    =     10.3 : 1.0\n              astounding = True              pos : neg    =     10.3 : 1.0\n                 idiotic = True              neg : pos    =      9.8 : 1.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Accuracy can be a very misleading term",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# For instance, say we want to build a tagger which tags parts of speech\n# Now, say that only 10% of the dataset consists of nouns\n# Also work under the assumption that the tagger fails to classify any noun\n\n# Thus, it's accuracy would be 90%, which is a misleading number,\n# beacuse it's accuracy for nouns would be 0.\n# As such, it is not a good representation of efficiency of a system.\n\n# Thus, we should look at measures such as precision, recall, and F-Measure\n# F-Measure is the harmonic mean of precision and recall\n    \nimport collections\nfrom collections import defaultdict\nfrom nltk.metrics import *\n\n\nrefsets = collections.defaultdict(set)\ntestsets = collections.defaultdict(set)\n \nfor i, (feats, label) in enumerate(testfeats):\n    refsets[label].add(i)\n    observed = classifier.classify(feats)\n    testsets[observed].add(i)\n    \n    \n    \n\n\nprint('pos precision:', nltk.metrics.precision(refsets['pos'], testsets['pos']))\nprint('pos recall:', nltk.metrics.recall(refsets['pos'], testsets['pos']))\nprint('pos F-measure:', nltk.metrics.f_measure(refsets['pos'], testsets['pos']))\nprint('neg precision:', nltk.metrics.precision(refsets['neg'], testsets['neg']))\nprint('neg recall:', nltk.metrics.recall(refsets['neg'], testsets['neg']))\nprint('neg F-measure:', nltk.metrics.f_measure(refsets['neg'], testsets['neg']))",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'nltk.translate.metrics' has no attribute 'precision'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-97c9e8823b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos recall:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos F-measure:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_measure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'nltk.translate.metrics' has no attribute 'precision'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
